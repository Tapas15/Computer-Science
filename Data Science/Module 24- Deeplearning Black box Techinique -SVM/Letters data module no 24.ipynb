{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Letter Support vector machine classifier module no 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"letterdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  letter  xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  xybar  \\\n",
       "0      T     2     8      3       5      1     8    13      0      6      6   \n",
       "1      I     5    12      3       7      2    10     5      5      4     13   \n",
       "2      D     4    11      6       8      6    10     6      2      6     10   \n",
       "3      N     7    11      6       6      3     5     9      4      6      4   \n",
       "4      G     2     1      3       1      1     8     6      6      6      6   \n",
       "\n",
       "   x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
       "0      10       8      0       8      0       8  \n",
       "1       3       9      2       8      4      10  \n",
       "2       3       7      3       7      3       9  \n",
       "3       4      10      6      10      2       8  \n",
       "4       5       9      1       7      5      10  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>xbox</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.757793</td>\n",
       "      <td>0.851514</td>\n",
       "      <td>0.672764</td>\n",
       "      <td>0.619097</td>\n",
       "      <td>-0.032595</td>\n",
       "      <td>0.045545</td>\n",
       "      <td>0.014306</td>\n",
       "      <td>0.052086</td>\n",
       "      <td>0.148056</td>\n",
       "      <td>0.035464</td>\n",
       "      <td>-0.046333</td>\n",
       "      <td>0.489155</td>\n",
       "      <td>0.098180</td>\n",
       "      <td>0.273504</td>\n",
       "      <td>-0.105147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ybox</th>\n",
       "      <td>0.757793</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.671912</td>\n",
       "      <td>0.823207</td>\n",
       "      <td>0.555067</td>\n",
       "      <td>0.045690</td>\n",
       "      <td>-0.040925</td>\n",
       "      <td>-0.025019</td>\n",
       "      <td>0.096478</td>\n",
       "      <td>0.159954</td>\n",
       "      <td>-0.054648</td>\n",
       "      <td>-0.007568</td>\n",
       "      <td>0.274431</td>\n",
       "      <td>-0.001336</td>\n",
       "      <td>0.230883</td>\n",
       "      <td>-0.042741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>width</th>\n",
       "      <td>0.851514</td>\n",
       "      <td>0.671912</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.660215</td>\n",
       "      <td>0.765716</td>\n",
       "      <td>0.061959</td>\n",
       "      <td>0.024832</td>\n",
       "      <td>-0.098611</td>\n",
       "      <td>0.057074</td>\n",
       "      <td>0.115018</td>\n",
       "      <td>0.011694</td>\n",
       "      <td>-0.045009</td>\n",
       "      <td>0.557251</td>\n",
       "      <td>0.045658</td>\n",
       "      <td>0.260285</td>\n",
       "      <td>-0.118273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>height</th>\n",
       "      <td>0.672764</td>\n",
       "      <td>0.823207</td>\n",
       "      <td>0.660215</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.644366</td>\n",
       "      <td>0.042844</td>\n",
       "      <td>-0.020072</td>\n",
       "      <td>0.082383</td>\n",
       "      <td>0.059032</td>\n",
       "      <td>0.012458</td>\n",
       "      <td>-0.011991</td>\n",
       "      <td>0.026386</td>\n",
       "      <td>0.265243</td>\n",
       "      <td>0.025359</td>\n",
       "      <td>0.297545</td>\n",
       "      <td>-0.018853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onpix</th>\n",
       "      <td>0.619097</td>\n",
       "      <td>0.555067</td>\n",
       "      <td>0.765716</td>\n",
       "      <td>0.644366</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.139159</td>\n",
       "      <td>-0.028822</td>\n",
       "      <td>-0.011985</td>\n",
       "      <td>-0.065557</td>\n",
       "      <td>-0.069776</td>\n",
       "      <td>-0.072941</td>\n",
       "      <td>-0.038858</td>\n",
       "      <td>0.627507</td>\n",
       "      <td>0.017649</td>\n",
       "      <td>0.492653</td>\n",
       "      <td>-0.062969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xbar</th>\n",
       "      <td>-0.032595</td>\n",
       "      <td>0.045690</td>\n",
       "      <td>0.061959</td>\n",
       "      <td>0.042844</td>\n",
       "      <td>0.139159</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.356580</td>\n",
       "      <td>-0.053306</td>\n",
       "      <td>-0.122851</td>\n",
       "      <td>0.085963</td>\n",
       "      <td>-0.341957</td>\n",
       "      <td>-0.032115</td>\n",
       "      <td>0.144325</td>\n",
       "      <td>-0.253339</td>\n",
       "      <td>0.127056</td>\n",
       "      <td>0.248816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ybar</th>\n",
       "      <td>0.045545</td>\n",
       "      <td>-0.040925</td>\n",
       "      <td>0.024832</td>\n",
       "      <td>-0.020072</td>\n",
       "      <td>-0.028822</td>\n",
       "      <td>-0.356580</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.118625</td>\n",
       "      <td>-0.049658</td>\n",
       "      <td>0.178318</td>\n",
       "      <td>0.600397</td>\n",
       "      <td>-0.271649</td>\n",
       "      <td>-0.036722</td>\n",
       "      <td>0.555060</td>\n",
       "      <td>-0.078008</td>\n",
       "      <td>-0.207900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2bar</th>\n",
       "      <td>0.014306</td>\n",
       "      <td>-0.025019</td>\n",
       "      <td>-0.098611</td>\n",
       "      <td>0.082383</td>\n",
       "      <td>-0.011985</td>\n",
       "      <td>-0.053306</td>\n",
       "      <td>-0.118625</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.188431</td>\n",
       "      <td>-0.317780</td>\n",
       "      <td>0.042545</td>\n",
       "      <td>0.082020</td>\n",
       "      <td>0.142132</td>\n",
       "      <td>-0.084820</td>\n",
       "      <td>0.006546</td>\n",
       "      <td>0.182902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y2bar</th>\n",
       "      <td>0.052086</td>\n",
       "      <td>0.096478</td>\n",
       "      <td>0.057074</td>\n",
       "      <td>0.059032</td>\n",
       "      <td>-0.065557</td>\n",
       "      <td>-0.122851</td>\n",
       "      <td>-0.049658</td>\n",
       "      <td>-0.188431</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.132000</td>\n",
       "      <td>-0.060116</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>-0.384018</td>\n",
       "      <td>-0.052545</td>\n",
       "      <td>0.277540</td>\n",
       "      <td>-0.061335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xybar</th>\n",
       "      <td>0.148056</td>\n",
       "      <td>0.159954</td>\n",
       "      <td>0.115018</td>\n",
       "      <td>0.012458</td>\n",
       "      <td>-0.069776</td>\n",
       "      <td>0.085963</td>\n",
       "      <td>0.178318</td>\n",
       "      <td>-0.317780</td>\n",
       "      <td>0.132000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.057988</td>\n",
       "      <td>-0.106759</td>\n",
       "      <td>-0.175676</td>\n",
       "      <td>0.029419</td>\n",
       "      <td>-0.087019</td>\n",
       "      <td>-0.114223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2ybar</th>\n",
       "      <td>0.035464</td>\n",
       "      <td>-0.054648</td>\n",
       "      <td>0.011694</td>\n",
       "      <td>-0.011991</td>\n",
       "      <td>-0.072941</td>\n",
       "      <td>-0.341957</td>\n",
       "      <td>0.600397</td>\n",
       "      <td>0.042545</td>\n",
       "      <td>-0.060116</td>\n",
       "      <td>0.057988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.063214</td>\n",
       "      <td>0.053566</td>\n",
       "      <td>0.527239</td>\n",
       "      <td>-0.226251</td>\n",
       "      <td>-0.236518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xy2bar</th>\n",
       "      <td>-0.046333</td>\n",
       "      <td>-0.007568</td>\n",
       "      <td>-0.045009</td>\n",
       "      <td>0.026386</td>\n",
       "      <td>-0.038858</td>\n",
       "      <td>-0.032115</td>\n",
       "      <td>-0.271649</td>\n",
       "      <td>0.082020</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>-0.106759</td>\n",
       "      <td>0.063214</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.008753</td>\n",
       "      <td>-0.184927</td>\n",
       "      <td>0.049695</td>\n",
       "      <td>0.245808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xedge</th>\n",
       "      <td>0.489155</td>\n",
       "      <td>0.274431</td>\n",
       "      <td>0.557251</td>\n",
       "      <td>0.265243</td>\n",
       "      <td>0.627507</td>\n",
       "      <td>0.144325</td>\n",
       "      <td>-0.036722</td>\n",
       "      <td>0.142132</td>\n",
       "      <td>-0.384018</td>\n",
       "      <td>-0.175676</td>\n",
       "      <td>0.053566</td>\n",
       "      <td>-0.008753</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>0.108411</td>\n",
       "      <td>-0.049789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xedgey</th>\n",
       "      <td>0.098180</td>\n",
       "      <td>-0.001336</td>\n",
       "      <td>0.045658</td>\n",
       "      <td>0.025359</td>\n",
       "      <td>0.017649</td>\n",
       "      <td>-0.253339</td>\n",
       "      <td>0.555060</td>\n",
       "      <td>-0.084820</td>\n",
       "      <td>-0.052545</td>\n",
       "      <td>0.029419</td>\n",
       "      <td>0.527239</td>\n",
       "      <td>-0.184927</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.064402</td>\n",
       "      <td>-0.187591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yedge</th>\n",
       "      <td>0.273504</td>\n",
       "      <td>0.230883</td>\n",
       "      <td>0.260285</td>\n",
       "      <td>0.297545</td>\n",
       "      <td>0.492653</td>\n",
       "      <td>0.127056</td>\n",
       "      <td>-0.078008</td>\n",
       "      <td>0.006546</td>\n",
       "      <td>0.277540</td>\n",
       "      <td>-0.087019</td>\n",
       "      <td>-0.226251</td>\n",
       "      <td>0.049695</td>\n",
       "      <td>0.108411</td>\n",
       "      <td>-0.064402</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.143588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yedgex</th>\n",
       "      <td>-0.105147</td>\n",
       "      <td>-0.042741</td>\n",
       "      <td>-0.118273</td>\n",
       "      <td>-0.018853</td>\n",
       "      <td>-0.062969</td>\n",
       "      <td>0.248816</td>\n",
       "      <td>-0.207900</td>\n",
       "      <td>0.182902</td>\n",
       "      <td>-0.061335</td>\n",
       "      <td>-0.114223</td>\n",
       "      <td>-0.236518</td>\n",
       "      <td>0.245808</td>\n",
       "      <td>-0.049789</td>\n",
       "      <td>-0.187591</td>\n",
       "      <td>0.143588</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            xbox      ybox     width    height     onpix      xbar      ybar  \\\n",
       "xbox    1.000000  0.757793  0.851514  0.672764  0.619097 -0.032595  0.045545   \n",
       "ybox    0.757793  1.000000  0.671912  0.823207  0.555067  0.045690 -0.040925   \n",
       "width   0.851514  0.671912  1.000000  0.660215  0.765716  0.061959  0.024832   \n",
       "height  0.672764  0.823207  0.660215  1.000000  0.644366  0.042844 -0.020072   \n",
       "onpix   0.619097  0.555067  0.765716  0.644366  1.000000  0.139159 -0.028822   \n",
       "xbar   -0.032595  0.045690  0.061959  0.042844  0.139159  1.000000 -0.356580   \n",
       "ybar    0.045545 -0.040925  0.024832 -0.020072 -0.028822 -0.356580  1.000000   \n",
       "x2bar   0.014306 -0.025019 -0.098611  0.082383 -0.011985 -0.053306 -0.118625   \n",
       "y2bar   0.052086  0.096478  0.057074  0.059032 -0.065557 -0.122851 -0.049658   \n",
       "xybar   0.148056  0.159954  0.115018  0.012458 -0.069776  0.085963  0.178318   \n",
       "x2ybar  0.035464 -0.054648  0.011694 -0.011991 -0.072941 -0.341957  0.600397   \n",
       "xy2bar -0.046333 -0.007568 -0.045009  0.026386 -0.038858 -0.032115 -0.271649   \n",
       "xedge   0.489155  0.274431  0.557251  0.265243  0.627507  0.144325 -0.036722   \n",
       "xedgey  0.098180 -0.001336  0.045658  0.025359  0.017649 -0.253339  0.555060   \n",
       "yedge   0.273504  0.230883  0.260285  0.297545  0.492653  0.127056 -0.078008   \n",
       "yedgex -0.105147 -0.042741 -0.118273 -0.018853 -0.062969  0.248816 -0.207900   \n",
       "\n",
       "           x2bar     y2bar     xybar    x2ybar    xy2bar     xedge    xedgey  \\\n",
       "xbox    0.014306  0.052086  0.148056  0.035464 -0.046333  0.489155  0.098180   \n",
       "ybox   -0.025019  0.096478  0.159954 -0.054648 -0.007568  0.274431 -0.001336   \n",
       "width  -0.098611  0.057074  0.115018  0.011694 -0.045009  0.557251  0.045658   \n",
       "height  0.082383  0.059032  0.012458 -0.011991  0.026386  0.265243  0.025359   \n",
       "onpix  -0.011985 -0.065557 -0.069776 -0.072941 -0.038858  0.627507  0.017649   \n",
       "xbar   -0.053306 -0.122851  0.085963 -0.341957 -0.032115  0.144325 -0.253339   \n",
       "ybar   -0.118625 -0.049658  0.178318  0.600397 -0.271649 -0.036722  0.555060   \n",
       "x2bar   1.000000 -0.188431 -0.317780  0.042545  0.082020  0.142132 -0.084820   \n",
       "y2bar  -0.188431  1.000000  0.132000 -0.060116  0.119048 -0.384018 -0.052545   \n",
       "xybar  -0.317780  0.132000  1.000000  0.057988 -0.106759 -0.175676  0.029419   \n",
       "x2ybar  0.042545 -0.060116  0.057988  1.000000  0.063214  0.053566  0.527239   \n",
       "xy2bar  0.082020  0.119048 -0.106759  0.063214  1.000000 -0.008753 -0.184927   \n",
       "xedge   0.142132 -0.384018 -0.175676  0.053566 -0.008753  1.000000  0.002849   \n",
       "xedgey -0.084820 -0.052545  0.029419  0.527239 -0.184927  0.002849  1.000000   \n",
       "yedge   0.006546  0.277540 -0.087019 -0.226251  0.049695  0.108411 -0.064402   \n",
       "yedgex  0.182902 -0.061335 -0.114223 -0.236518  0.245808 -0.049789 -0.187591   \n",
       "\n",
       "           yedge    yedgex  \n",
       "xbox    0.273504 -0.105147  \n",
       "ybox    0.230883 -0.042741  \n",
       "width   0.260285 -0.118273  \n",
       "height  0.297545 -0.018853  \n",
       "onpix   0.492653 -0.062969  \n",
       "xbar    0.127056  0.248816  \n",
       "ybar   -0.078008 -0.207900  \n",
       "x2bar   0.006546  0.182902  \n",
       "y2bar   0.277540 -0.061335  \n",
       "xybar  -0.087019 -0.114223  \n",
       "x2ybar -0.226251 -0.236518  \n",
       "xy2bar  0.049695  0.245808  \n",
       "xedge   0.108411 -0.049789  \n",
       "xedgey -0.064402 -0.187591  \n",
       "yedge   1.000000  0.143588  \n",
       "yedgex  0.143588  1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 17)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 17 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   letter  20000 non-null  object\n",
      " 1   xbox    20000 non-null  int64 \n",
      " 2   ybox    20000 non-null  int64 \n",
      " 3   width   20000 non-null  int64 \n",
      " 4   height  20000 non-null  int64 \n",
      " 5   onpix   20000 non-null  int64 \n",
      " 6   xbar    20000 non-null  int64 \n",
      " 7   ybar    20000 non-null  int64 \n",
      " 8   x2bar   20000 non-null  int64 \n",
      " 9   y2bar   20000 non-null  int64 \n",
      " 10  xybar   20000 non-null  int64 \n",
      " 11  x2ybar  20000 non-null  int64 \n",
      " 12  xy2bar  20000 non-null  int64 \n",
      " 13  xedge   20000 non-null  int64 \n",
      " 14  xedgey  20000 non-null  int64 \n",
      " 15  yedge   20000 non-null  int64 \n",
      " 16  yedgex  20000 non-null  int64 \n",
      "dtypes: int64(16), object(1)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "letter    0\n",
       "xbox      0\n",
       "ybox      0\n",
       "width     0\n",
       "height    0\n",
       "onpix     0\n",
       "xbar      0\n",
       "ybar      0\n",
       "x2bar     0\n",
       "y2bar     0\n",
       "xybar     0\n",
       "x2ybar    0\n",
       "xy2bar    0\n",
       "xedge     0\n",
       "xedgey    0\n",
       "yedge     0\n",
       "yedgex    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() # there is no na value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20000.00</td>\n",
       "      <td>20000.00</td>\n",
       "      <td>20000.00</td>\n",
       "      <td>20000.00</td>\n",
       "      <td>20000.00</td>\n",
       "      <td>20000.00</td>\n",
       "      <td>20000.00</td>\n",
       "      <td>20000.00</td>\n",
       "      <td>20000.00</td>\n",
       "      <td>20000.00</td>\n",
       "      <td>20000.00</td>\n",
       "      <td>20000.00</td>\n",
       "      <td>20000.00</td>\n",
       "      <td>20000.00</td>\n",
       "      <td>20000.00</td>\n",
       "      <td>20000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.02</td>\n",
       "      <td>7.04</td>\n",
       "      <td>5.12</td>\n",
       "      <td>5.37</td>\n",
       "      <td>3.51</td>\n",
       "      <td>6.90</td>\n",
       "      <td>7.50</td>\n",
       "      <td>4.63</td>\n",
       "      <td>5.18</td>\n",
       "      <td>8.28</td>\n",
       "      <td>6.45</td>\n",
       "      <td>7.93</td>\n",
       "      <td>3.05</td>\n",
       "      <td>8.34</td>\n",
       "      <td>3.69</td>\n",
       "      <td>7.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.91</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.01</td>\n",
       "      <td>2.26</td>\n",
       "      <td>2.19</td>\n",
       "      <td>2.03</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.70</td>\n",
       "      <td>2.38</td>\n",
       "      <td>2.49</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.08</td>\n",
       "      <td>2.33</td>\n",
       "      <td>1.55</td>\n",
       "      <td>2.57</td>\n",
       "      <td>1.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>9.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>15.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           xbox      ybox     width    height     onpix      xbar      ybar  \\\n",
       "count  20000.00  20000.00  20000.00  20000.00  20000.00  20000.00  20000.00   \n",
       "mean       4.02      7.04      5.12      5.37      3.51      6.90      7.50   \n",
       "std        1.91      3.30      2.01      2.26      2.19      2.03      2.33   \n",
       "min        0.00      0.00      0.00      0.00      0.00      0.00      0.00   \n",
       "25%        3.00      5.00      4.00      4.00      2.00      6.00      6.00   \n",
       "50%        4.00      7.00      5.00      6.00      3.00      7.00      7.00   \n",
       "75%        5.00      9.00      6.00      7.00      5.00      8.00      9.00   \n",
       "max       15.00     15.00     15.00     15.00     15.00     15.00     15.00   \n",
       "\n",
       "          x2bar     y2bar     xybar    x2ybar    xy2bar     xedge    xedgey  \\\n",
       "count  20000.00  20000.00  20000.00  20000.00  20000.00  20000.00  20000.00   \n",
       "mean       4.63      5.18      8.28      6.45      7.93      3.05      8.34   \n",
       "std        2.70      2.38      2.49      2.63      2.08      2.33      1.55   \n",
       "min        0.00      0.00      0.00      0.00      0.00      0.00      0.00   \n",
       "25%        3.00      4.00      7.00      5.00      7.00      1.00      8.00   \n",
       "50%        4.00      5.00      8.00      6.00      8.00      3.00      8.00   \n",
       "75%        6.00      7.00     10.00      8.00      9.00      4.00      9.00   \n",
       "max       15.00     15.00     15.00     15.00     15.00     15.00     15.00   \n",
       "\n",
       "          yedge    yedgex  \n",
       "count  20000.00  20000.00  \n",
       "mean       3.69      7.80  \n",
       "std        2.57      1.62  \n",
       "min        0.00      0.00  \n",
       "25%        2.00      7.00  \n",
       "50%        3.00      8.00  \n",
       "75%        5.00      9.00  \n",
       "max       15.00     15.00  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(df.describe(),2) # description of data and its spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "U    813\n",
       "D    805\n",
       "P    803\n",
       "T    796\n",
       "M    792\n",
       "A    789\n",
       "X    787\n",
       "Y    786\n",
       "Q    783\n",
       "N    783\n",
       "F    775\n",
       "G    773\n",
       "E    768\n",
       "B    766\n",
       "V    764\n",
       "L    761\n",
       "R    758\n",
       "I    755\n",
       "O    753\n",
       "W    752\n",
       "S    748\n",
       "J    747\n",
       "K    739\n",
       "C    736\n",
       "H    734\n",
       "Z    734\n",
       "Name: letter, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['letter'].value_counts() # value count of letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21b5e965c88>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x=\"letter\",y=\"xbox\",data=df,palette = \"hls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21b643e1988>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x=\"ybox\",y=\"letter\",data=df,palette = \"hls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featurs Scalling  of our data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(df.drop('letter',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_features = scaler.transform(df.drop('letter',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.057698</td>\n",
       "      <td>0.291877</td>\n",
       "      <td>-1.053277</td>\n",
       "      <td>-0.164704</td>\n",
       "      <td>-1.144013</td>\n",
       "      <td>0.544130</td>\n",
       "      <td>2.365097</td>\n",
       "      <td>-1.714360</td>\n",
       "      <td>0.344994</td>\n",
       "      <td>-0.917071</td>\n",
       "      <td>1.347774</td>\n",
       "      <td>0.034125</td>\n",
       "      <td>-1.305948</td>\n",
       "      <td>-0.219082</td>\n",
       "      <td>-1.438153</td>\n",
       "      <td>0.122911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.510385</td>\n",
       "      <td>1.502358</td>\n",
       "      <td>-1.053277</td>\n",
       "      <td>0.719730</td>\n",
       "      <td>-0.687476</td>\n",
       "      <td>1.531305</td>\n",
       "      <td>-1.075326</td>\n",
       "      <td>0.137561</td>\n",
       "      <td>-0.495072</td>\n",
       "      <td>1.895968</td>\n",
       "      <td>-1.312807</td>\n",
       "      <td>0.514764</td>\n",
       "      <td>-0.448492</td>\n",
       "      <td>-0.219082</td>\n",
       "      <td>0.120081</td>\n",
       "      <td>1.359441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.012309</td>\n",
       "      <td>1.199738</td>\n",
       "      <td>0.435910</td>\n",
       "      <td>1.161947</td>\n",
       "      <td>1.138672</td>\n",
       "      <td>1.531305</td>\n",
       "      <td>-0.645273</td>\n",
       "      <td>-0.973591</td>\n",
       "      <td>0.344994</td>\n",
       "      <td>0.690380</td>\n",
       "      <td>-1.312807</td>\n",
       "      <td>-0.446513</td>\n",
       "      <td>-0.019764</td>\n",
       "      <td>-0.865626</td>\n",
       "      <td>-0.269477</td>\n",
       "      <td>0.741176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.555774</td>\n",
       "      <td>1.199738</td>\n",
       "      <td>0.435910</td>\n",
       "      <td>0.277513</td>\n",
       "      <td>-0.230939</td>\n",
       "      <td>-0.936631</td>\n",
       "      <td>0.644886</td>\n",
       "      <td>-0.232823</td>\n",
       "      <td>0.344994</td>\n",
       "      <td>-1.720796</td>\n",
       "      <td>-0.932724</td>\n",
       "      <td>0.995402</td>\n",
       "      <td>1.266419</td>\n",
       "      <td>1.074008</td>\n",
       "      <td>-0.659036</td>\n",
       "      <td>0.122911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.057698</td>\n",
       "      <td>-1.826464</td>\n",
       "      <td>-1.053277</td>\n",
       "      <td>-1.933571</td>\n",
       "      <td>-1.144013</td>\n",
       "      <td>0.544130</td>\n",
       "      <td>-0.645273</td>\n",
       "      <td>0.507945</td>\n",
       "      <td>0.344994</td>\n",
       "      <td>-0.917071</td>\n",
       "      <td>-0.552641</td>\n",
       "      <td>0.514764</td>\n",
       "      <td>-0.877220</td>\n",
       "      <td>-0.865626</td>\n",
       "      <td>0.509640</td>\n",
       "      <td>1.359441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     letter      xbox      ybox     width    height     onpix      xbar  \\\n",
       "0 -1.057698  0.291877 -1.053277 -0.164704 -1.144013  0.544130  2.365097   \n",
       "1  0.510385  1.502358 -1.053277  0.719730 -0.687476  1.531305 -1.075326   \n",
       "2 -0.012309  1.199738  0.435910  1.161947  1.138672  1.531305 -0.645273   \n",
       "3  1.555774  1.199738  0.435910  0.277513 -0.230939 -0.936631  0.644886   \n",
       "4 -1.057698 -1.826464 -1.053277 -1.933571 -1.144013  0.544130 -0.645273   \n",
       "\n",
       "       ybar     x2bar     y2bar     xybar    x2ybar    xy2bar     xedge  \\\n",
       "0 -1.714360  0.344994 -0.917071  1.347774  0.034125 -1.305948 -0.219082   \n",
       "1  0.137561 -0.495072  1.895968 -1.312807  0.514764 -0.448492 -0.219082   \n",
       "2 -0.973591  0.344994  0.690380 -1.312807 -0.446513 -0.019764 -0.865626   \n",
       "3 -0.232823  0.344994 -1.720796 -0.932724  0.995402  1.266419  1.074008   \n",
       "4  0.507945  0.344994 -0.917071 -0.552641  0.514764 -0.877220 -0.865626   \n",
       "\n",
       "     xedgey     yedge  \n",
       "0 -1.438153  0.122911  \n",
       "1  0.120081  1.359441  \n",
       "2 -0.269477  0.741176  \n",
       "3 -0.659036  0.122911  \n",
       "4  0.509640  1.359441  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat = pd.DataFrame(scaled_features,columns=df.columns[:-1])\n",
    "df_feat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaled_features\n",
    "y = df['letter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Classifiers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import SVC classifier\n",
    "from sklearn.svm import SVC\n",
    "#import metrics to compute accuracy\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiacte classifier\n",
    "svc = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction and Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[260   0   2   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  1 242   0   4   1   2   0   0   0   0   0   0   0   0   0   0   0   3\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0 190   0   5   0   5   1   0   0   1   0   1   0   7   0   0   1\n",
      "    0   0   1   0   1   0   0   0]\n",
      " [  0   2   0 274   0   0   0   3   0   0   0   0   0   1   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   3   0 242   0   7   0   0   0   0   0   0   0   0   0   2   0\n",
      "    0   0   0   0   0   0   0   3]\n",
      " [  0   1   0   0   1 225   0   0   1   0   0   0   0   0   0   0   0   0\n",
      "    0   4   0   0   0   0   0   0]\n",
      " [  0   0   1   4   0   0 234   0   0   0   0   1   0   0   0   0   1   2\n",
      "    0   0   0   2   0   0   0   0]\n",
      " [  0   6   0  11   0   0   4 182   0   0   5   0   0   1   5   1   4  15\n",
      "    0   0   1   0   0   1   2   0]\n",
      " [  0   0   0   0   0   3   0   0 223  10   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   3   0   0]\n",
      " [  1   0   0   1   1   1   0   1   5 230   0   0   0   0   3   0   0   0\n",
      "    0   0   0   0   0   1   0   1]\n",
      " [  0   0   2   2   0   0   0   0   0   0 182   0   0   0   0   0   0  15\n",
      "    0   0   0   0   0   2   0   0]\n",
      " [  0   0   1   0   6   0   5   0   0   0   0 232   0   0   0   0   1   2\n",
      "    1   0   0   0   0   0   0   0]\n",
      " [  1   3   0   0   0   0   1   0   0   0   0   0 268   0   1   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   2   0   3   0   0   0   1   0   0   0   0   3 234   5   0   0   5\n",
      "    0   0   0   0   1   0   0   0]\n",
      " [  0   0   0   4   0   0   0   0   0   0   0   0   0   0 230   0   5   3\n",
      "    0   0   1   0   5   0   0   0]\n",
      " [  0   2   0   1   2  16   5   0   0   0   0   1   0   0   2 246   0   0\n",
      "    0   0   0   0   0   0   2   0]\n",
      " [  0   3   0   1   2   0   1   0   0   0   0   0   0   0   4   0 265   1\n",
      "    0   0   0   0   2   0   0   0]\n",
      " [  0   8   1   1   0   0   0   2   0   0   3   0   0   5   0   0   0 234\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   2   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  247   0   0   0   0   2   0   1]\n",
      " [  0   0   0   0   1   0   0   2   0   0   1   0   0   0   0   0   0   3\n",
      "    0 246   1   0   0   3   1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   4   0   5   0   0   0   0   0\n",
      "    0   0 279   2   3   0   0   0]\n",
      " [  1   4   0   0   0   1   0   1   0   0   0   0   1   0   0   0   0   1\n",
      "    0   0   0 254   1   0   3   0]\n",
      " [  0   0   0   0   0   0   1   1   0   0   0   0   1   0   1   0   0   0\n",
      "    0   0   2   0 231   0   0   0]\n",
      " [  0   1   0   3   0   0   0   0   0   0   2   0   0   0   0   0   0   1\n",
      "    0   1   0   0   0 266   1   0]\n",
      " [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   1   0   1   0   0 269   0]\n",
      " [  0   0   0   0   0   0   0   0   0   3   0   1   0   0   0   0   2   1\n",
      "    3   0   0   0   0   0   0 230]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.98      0.98      0.98       264\n",
      "           B       0.88      0.96      0.91       253\n",
      "           C       0.95      0.89      0.92       213\n",
      "           D       0.89      0.97      0.93       282\n",
      "           E       0.92      0.94      0.93       257\n",
      "           F       0.90      0.97      0.94       232\n",
      "           G       0.89      0.96      0.92       245\n",
      "           H       0.94      0.76      0.84       238\n",
      "           I       0.97      0.93      0.95       239\n",
      "           J       0.95      0.94      0.94       245\n",
      "           K       0.92      0.90      0.91       203\n",
      "           L       0.99      0.94      0.96       248\n",
      "           M       0.95      0.98      0.97       274\n",
      "           N       0.97      0.92      0.95       254\n",
      "           O       0.88      0.93      0.91       248\n",
      "           P       1.00      0.89      0.94       277\n",
      "           Q       0.95      0.95      0.95       279\n",
      "           R       0.82      0.92      0.87       254\n",
      "           S       0.98      0.98      0.98       253\n",
      "           T       0.98      0.95      0.96       258\n",
      "           U       0.98      0.95      0.97       293\n",
      "           V       0.98      0.95      0.97       267\n",
      "           W       0.95      0.97      0.96       237\n",
      "           X       0.96      0.97      0.96       275\n",
      "           Y       0.97      0.99      0.98       272\n",
      "           Z       0.98      0.96      0.97       240\n",
      "\n",
      "    accuracy                           0.94      6600\n",
      "   macro avg       0.94      0.94      0.94      6600\n",
      "weighted avg       0.94      0.94      0.94      6600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy Score: 0.9417\n"
     ]
    }
   ],
   "source": [
    "print('Model Accuracy Score: {0:0.4f}'.format(accuracy_score(y_test,predictions))) # Accuracy predictions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Classification SVM classification linear  object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM classifiction linear Kernel object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SVC in module sklearn.svm._classes:\n",
      "\n",
      "class SVC(sklearn.svm._base.BaseSVC)\n",
      " |  SVC(C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None)\n",
      " |  \n",
      " |  C-Support Vector Classification.\n",
      " |  \n",
      " |  The implementation is based on libsvm. The fit time scales at least\n",
      " |  quadratically with the number of samples and may be impractical\n",
      " |  beyond tens of thousands of samples. For large datasets\n",
      " |  consider using :class:`sklearn.svm.LinearSVC` or\n",
      " |  :class:`sklearn.linear_model.SGDClassifier` instead, possibly after a\n",
      " |  :class:`sklearn.kernel_approximation.Nystroem` transformer.\n",
      " |  \n",
      " |  The multiclass support is handled according to a one-vs-one scheme.\n",
      " |  \n",
      " |  For details on the precise mathematical formulation of the provided\n",
      " |  kernel functions and how `gamma`, `coef0` and `degree` affect each\n",
      " |  other, see the corresponding section in the narrative documentation:\n",
      " |  :ref:`svm_kernels`.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <svm_classification>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  C : float, optional (default=1.0)\n",
      " |      Regularization parameter. The strength of the regularization is\n",
      " |      inversely proportional to C. Must be strictly positive. The penalty\n",
      " |      is a squared l2 penalty.\n",
      " |  \n",
      " |  kernel : string, optional (default='rbf')\n",
      " |      Specifies the kernel type to be used in the algorithm.\n",
      " |      It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\n",
      " |      a callable.\n",
      " |      If none is given, 'rbf' will be used. If a callable is given it is\n",
      " |      used to pre-compute the kernel matrix from data matrices; that matrix\n",
      " |      should be an array of shape ``(n_samples, n_samples)``.\n",
      " |  \n",
      " |  degree : int, optional (default=3)\n",
      " |      Degree of the polynomial kernel function ('poly').\n",
      " |      Ignored by all other kernels.\n",
      " |  \n",
      " |  gamma : {'scale', 'auto'} or float, optional (default='scale')\n",
      " |      Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
      " |  \n",
      " |      - if ``gamma='scale'`` (default) is passed then it uses\n",
      " |        1 / (n_features * X.var()) as value of gamma,\n",
      " |      - if 'auto', uses 1 / n_features.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |         The default value of ``gamma`` changed from 'auto' to 'scale'.\n",
      " |  \n",
      " |  coef0 : float, optional (default=0.0)\n",
      " |      Independent term in kernel function.\n",
      " |      It is only significant in 'poly' and 'sigmoid'.\n",
      " |  \n",
      " |  shrinking : boolean, optional (default=True)\n",
      " |      Whether to use the shrinking heuristic.\n",
      " |  \n",
      " |  probability : boolean, optional (default=False)\n",
      " |      Whether to enable probability estimates. This must be enabled prior\n",
      " |      to calling `fit`, will slow down that method as it internally uses\n",
      " |      5-fold cross-validation, and `predict_proba` may be inconsistent with\n",
      " |      `predict`. Read more in the :ref:`User Guide <scores_probabilities>`.\n",
      " |  \n",
      " |  tol : float, optional (default=1e-3)\n",
      " |      Tolerance for stopping criterion.\n",
      " |  \n",
      " |  cache_size : float, optional\n",
      " |      Specify the size of the kernel cache (in MB).\n",
      " |  \n",
      " |  class_weight : {dict, 'balanced'}, optional\n",
      " |      Set the parameter C of class i to class_weight[i]*C for\n",
      " |      SVC. If not given, all classes are supposed to have\n",
      " |      weight one.\n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``\n",
      " |  \n",
      " |  verbose : bool, default: False\n",
      " |      Enable verbose output. Note that this setting takes advantage of a\n",
      " |      per-process runtime setting in libsvm that, if enabled, may not work\n",
      " |      properly in a multithreaded context.\n",
      " |  \n",
      " |  max_iter : int, optional (default=-1)\n",
      " |      Hard limit on iterations within solver, or -1 for no limit.\n",
      " |  \n",
      " |  decision_function_shape : 'ovo', 'ovr', default='ovr'\n",
      " |      Whether to return a one-vs-rest ('ovr') decision function of shape\n",
      " |      (n_samples, n_classes) as all other classifiers, or the original\n",
      " |      one-vs-one ('ovo') decision function of libsvm which has shape\n",
      " |      (n_samples, n_classes * (n_classes - 1) / 2). However, one-vs-one\n",
      " |      ('ovo') is always used as multi-class strategy.\n",
      " |  \n",
      " |      .. versionchanged:: 0.19\n",
      " |          decision_function_shape is 'ovr' by default.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *decision_function_shape='ovr'* is recommended.\n",
      " |  \n",
      " |      .. versionchanged:: 0.17\n",
      " |         Deprecated *decision_function_shape='ovo' and None*.\n",
      " |  \n",
      " |  break_ties : bool, optional (default=False)\n",
      " |      If true, ``decision_function_shape='ovr'``, and number of classes > 2,\n",
      " |      :term:`predict` will break ties according to the confidence values of\n",
      " |      :term:`decision_function`; otherwise the first class among the tied\n",
      " |      classes is returned. Please note that breaking ties comes at a\n",
      " |      relatively high computational cost compared to a simple predict.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional (default=None)\n",
      " |      The seed of the pseudo random number generator used when shuffling\n",
      " |      the data for probability estimates. If int, random_state is the\n",
      " |      seed used by the random number generator; If RandomState instance,\n",
      " |      random_state is the random number generator; If None, the random\n",
      " |      number generator is the RandomState instance used by `np.random`.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  support_ : array-like of shape (n_SV)\n",
      " |      Indices of support vectors.\n",
      " |  \n",
      " |  support_vectors_ : array-like of shape (n_SV, n_features)\n",
      " |      Support vectors.\n",
      " |  \n",
      " |  n_support_ : array-like, dtype=int32, shape = [n_class]\n",
      " |      Number of support vectors for each class.\n",
      " |  \n",
      " |  dual_coef_ : array, shape = [n_class-1, n_SV]\n",
      " |      Coefficients of the support vector in the decision function.\n",
      " |      For multiclass, coefficient for all 1-vs-1 classifiers.\n",
      " |      The layout of the coefficients in the multiclass case is somewhat\n",
      " |      non-trivial. See the section about multi-class classification in the\n",
      " |      SVM section of the User Guide for details.\n",
      " |  \n",
      " |  coef_ : array, shape = [n_class * (n_class-1) / 2, n_features]\n",
      " |      Weights assigned to the features (coefficients in the primal\n",
      " |      problem). This is only available in the case of a linear kernel.\n",
      " |  \n",
      " |      `coef_` is a readonly property derived from `dual_coef_` and\n",
      " |      `support_vectors_`.\n",
      " |  \n",
      " |  intercept_ : ndarray of shape (n_class * (n_class-1) / 2,)\n",
      " |      Constants in decision function.\n",
      " |  \n",
      " |  fit_status_ : int\n",
      " |      0 if correctly fitted, 1 otherwise (will raise warning)\n",
      " |  \n",
      " |  classes_ : array of shape (n_classes,)\n",
      " |      The classes labels.\n",
      " |  \n",
      " |  probA_ : array, shape = [n_class * (n_class-1) / 2]\n",
      " |  probB_ : array, shape = [n_class * (n_class-1) / 2]\n",
      " |      If `probability=True`, it corresponds to the parameters learned in\n",
      " |      Platt scaling to produce probability estimates from decision values.\n",
      " |      If `probability=False`, it's an empty array. Platt scaling uses the\n",
      " |      logistic function\n",
      " |      ``1 / (1 + exp(decision_value * probA_ + probB_))``\n",
      " |      where ``probA_`` and ``probB_`` are learned from the dataset [2]_. For\n",
      " |      more information on the multiclass case and training procedure see\n",
      " |      section 8 of [1]_.\n",
      " |  \n",
      " |  class_weight_ : ndarray of shape (n_class,)\n",
      " |      Multipliers of parameter C for each class.\n",
      " |      Computed based on the ``class_weight`` parameter.\n",
      " |  \n",
      " |  shape_fit_ : tuple of int of shape (n_dimensions_of_X,)\n",
      " |      Array dimensions of training vector ``X``.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
      " |  >>> y = np.array([1, 1, 2, 2])\n",
      " |  >>> from sklearn.svm import SVC\n",
      " |  >>> clf = SVC(gamma='auto')\n",
      " |  >>> clf.fit(X, y)\n",
      " |  SVC(gamma='auto')\n",
      " |  >>> print(clf.predict([[-0.8, -1]]))\n",
      " |  [1]\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  SVR\n",
      " |      Support Vector Machine for Regression implemented using libsvm.\n",
      " |  \n",
      " |  LinearSVC\n",
      " |      Scalable Linear Support Vector Machine for classification\n",
      " |      implemented using liblinear. Check the See also section of\n",
      " |      LinearSVC for more comparison element.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  .. [1] `LIBSVM: A Library for Support Vector Machines\n",
      " |      <http://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf>`_\n",
      " |  \n",
      " |  .. [2] `Platt, John (1999). \"Probabilistic outputs for support vector\n",
      " |      machines and comparison to regularizedlikelihood methods.\"\n",
      " |      <http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.1639>`_\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SVC\n",
      " |      sklearn.svm._base.BaseSVC\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      sklearn.svm._base.BaseLibSVM\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.svm._base.BaseSVC:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Evaluates the decision function for the samples in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X : array-like, shape (n_samples, n_classes * (n_classes-1) / 2)\n",
      " |          Returns the decision function of the sample for each class\n",
      " |          in the model.\n",
      " |          If decision_function_shape='ovr', the shape is (n_samples,\n",
      " |          n_classes).\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If decision_function_shape='ovo', the function values are proportional\n",
      " |      to the distance of the samples X to the separating hyperplane. If the\n",
      " |      exact distances are required, divide the function values by the norm of\n",
      " |      the weight vector (``coef_``). See also `this question\n",
      " |      <https://stats.stackexchange.com/questions/14876/\n",
      " |      interpreting-distance-from-hyperplane-in-svm>`_ for further details.\n",
      " |      If decision_function_shape='ovr', the decision function is a monotonic\n",
      " |      transformation of ovo decision function.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Perform classification on samples in X.\n",
      " |      \n",
      " |      For an one-class model, +1 or -1 is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          [n_samples_test, n_samples_train]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : array, shape (n_samples,)\n",
      " |          Class labels for samples in X.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.svm._base.BaseSVC:\n",
      " |  \n",
      " |  predict_log_proba\n",
      " |      Compute log probabilities of possible outcomes for samples in X.\n",
      " |      \n",
      " |      The model need to have probability information computed at training\n",
      " |      time: fit with attribute `probability` set to True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          [n_samples_test, n_samples_train]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : array-like, shape (n_samples, n_classes)\n",
      " |          Returns the log-probabilities of the sample for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute :term:`classes_`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability model is created using cross validation, so\n",
      " |      the results can be slightly different than those obtained by\n",
      " |      predict. Also, it will produce meaningless results on very small\n",
      " |      datasets.\n",
      " |  \n",
      " |  predict_proba\n",
      " |      Compute probabilities of possible outcomes for samples in X.\n",
      " |      \n",
      " |      The model need to have probability information computed at training\n",
      " |      time: fit with attribute `probability` set to True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          [n_samples_test, n_samples_train]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : array-like, shape (n_samples, n_classes)\n",
      " |          Returns the probability of the sample for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute :term:`classes_`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability model is created using cross validation, so\n",
      " |      the results can be slightly different than those obtained by\n",
      " |      predict. Also, it will produce meaningless results on very small\n",
      " |      datasets.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.svm._base.BaseLibSVM:\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit the SVM model according to the given training data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          Training vectors, where n_samples is the number of samples\n",
      " |          and n_features is the number of features.\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples, n_samples).\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,)\n",
      " |          Target values (class labels in classification, real numbers in\n",
      " |          regression)\n",
      " |      \n",
      " |      sample_weight : array-like, shape (n_samples,)\n",
      " |          Per-sample weights. Rescale C per sample. Higher weights\n",
      " |          force the classifier to put more emphasis on these points.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If X and y are not C-ordered and contiguous arrays of np.float64 and\n",
      " |      X is not a scipy.sparse.csr_matrix, X and/or y may be copied.\n",
      " |      \n",
      " |      If X is a dense array, then the other methods will not support sparse\n",
      " |      matrices as input.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.svm._base.BaseLibSVM:\n",
      " |  \n",
      " |  coef_\n",
      " |  \n",
      " |  n_support_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_linear = SVC(kernel = \"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_linear.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_linear = model_linear.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8534848484848485"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(pred_test_linear==y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel poly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_poly = SVC(kernel = \"poly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='poly',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_poly.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_poly = model_poly.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8825757575757576"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(pred_test_poly==y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel RBF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rbf = SVC(kernel = \"rbf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rbf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicition and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_rbf = model_rbf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9416666666666667"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(pred_test_rbf==y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sig = SVC(kernel=\"sigmoid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='sigmoid',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sig.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicition and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_sig = model_sig.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46924242424242424"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(pred_test_sig==y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
